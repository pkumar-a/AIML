{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data points: 1212\n",
      "validation data points: 135\n",
      "testing data points: 450\n",
      "k=1, accuracy=99.26%\n",
      "k=3, accuracy=99.26%\n",
      "k=5, accuracy=99.26%\n",
      "k=7, accuracy=99.26%\n",
      "k=9, accuracy=99.26%\n",
      "k=11, accuracy=99.26%\n",
      "k=13, accuracy=99.26%\n",
      "k=15, accuracy=99.26%\n",
      "k=17, accuracy=98.52%\n",
      "k=19, accuracy=98.52%\n",
      "k=21, accuracy=97.78%\n",
      "k=23, accuracy=97.04%\n",
      "k=25, accuracy=97.78%\n",
      "k=27, accuracy=97.04%\n",
      "k=29, accuracy=97.04%\n",
      "k=1 achieved highest accuracy of 99.26% on validation data\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.97        37\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.98      0.98      0.98        46\n",
      "           4       0.98      0.98      0.98        55\n",
      "           5       0.98      1.00      0.99        59\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       1.00      0.98      0.99        41\n",
      "           8       0.97      0.95      0.96        38\n",
      "           9       0.96      0.94      0.95        48\n",
      "\n",
      "    accuracy                           0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n",
      "Confusion matrix\n",
      "[[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 37  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 38  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 45  0  0  0  0  1  0]\n",
      " [ 0  1  0  0 54  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 59  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 36  1]\n",
      " [ 0  0  0  1  1  1  0  0  0 45]]\n",
      "i think the digit is : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the MNIST digits dataset\n",
    "mnist = datasets.load_digits()\n",
    "\n",
    "# take the MNIST data and construct the training and testing split, using 75% of the\n",
    "# data for training and 25% for testing\n",
    "\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(mnist.data),\n",
    "mnist.target, test_size=0.25, random_state=42)\n",
    "\n",
    "# now, let's take 10% of the training data and use that for validation\n",
    "\n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(trainData, trainLabels,\n",
    "test_size=0.1, random_state=84)\n",
    "\n",
    "# show the sizes of each data split\n",
    "\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))\n",
    "\n",
    "# initialize the values of k for our k-Nearest Neighbor classifier along with the\n",
    "# list of accuracies for each value of k\n",
    "\n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    "\n",
    "# loop over various values of `k` for the k-Nearest Neighbor classifier\n",
    "\n",
    "for k in range(1, 30, 2):\n",
    "          # train the k-Nearest Neighbor classifier with the current value of `k`\n",
    "          model = KNeighborsClassifier(n_neighbors=k)\n",
    "          model.fit(trainData, trainLabels)\n",
    "          # evaluate the model and update the accuracies list\n",
    "          score = model.score(valData, valLabels)\n",
    "          print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "          accuracies.append(score)\n",
    "          \n",
    "# find the value of k that has the largest accuracy\n",
    "\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "accuracies[i] * 100))\n",
    "\n",
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "model.fit(trainData, trainLabels)\n",
    "predictions = model.predict(testData)\n",
    "#print(predictions[1])\n",
    "\n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "print(confusion_matrix(testLabels,predictions))\n",
    "\n",
    "# loop over a few random digits\n",
    "\n",
    "for i in np.random.randint(0, high=len(testLabels), size=(5,)):\n",
    "         # grab the image and classify it\n",
    "         image = testData[i]\n",
    "         prediction = model.predict([image])[0]\n",
    "         # convert the image for a 64-dim array to an 8 x 8 image compatible with OpenCV,\n",
    "         # then resize it to 32 x 32 pixels so we can see it better\n",
    "         image = image.reshape((8, 8))\n",
    "         image = exposure.rescale_intensity(image, out_range=(0, 255))\n",
    "         image = imutils.resize(image, width=32, inter=cv2.INTER_CUBIC)\n",
    "         \n",
    "         # show the prediction\n",
    "         \n",
    "         imgdata = np.array(image, dtype='float')\n",
    "         pixels = imgdata.reshape((32,32))\n",
    "         plt.imshow(pixels,cmap='gray')\n",
    "         plt.annotate(prediction,(3,3),bbox={'facecolor':'white'},fontsize=16)\n",
    "         print(\"i think the digit is : {}\".format(prediction))\n",
    "         #cv2.imshow(\"image\", image)\n",
    "         plt.show()\n",
    "         cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
