{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1       2       3        4        5        6        7       8   \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "          9   ...     21      22      23       24       25      26      27  \\\n",
       "0    0.07871  ...  17.33  184.60  2019.0  0.16220  0.66560  0.7119  0.2654   \n",
       "1    0.05667  ...  23.41  158.80  1956.0  0.12380  0.18660  0.2416  0.1860   \n",
       "2    0.05999  ...  25.53  152.50  1709.0  0.14440  0.42450  0.4504  0.2430   \n",
       "3    0.09744  ...  26.50   98.87   567.7  0.20980  0.86630  0.6869  0.2575   \n",
       "4    0.05883  ...  16.67  152.20  1575.0  0.13740  0.20500  0.4000  0.1625   \n",
       "..       ...  ...    ...     ...     ...      ...      ...     ...     ...   \n",
       "564  0.05623  ...  26.40  166.10  2027.0  0.14100  0.21130  0.4107  0.2216   \n",
       "565  0.05533  ...  38.25  155.00  1731.0  0.11660  0.19220  0.3215  0.1628   \n",
       "566  0.05648  ...  34.12  126.70  1124.0  0.11390  0.30940  0.3403  0.1418   \n",
       "567  0.07016  ...  39.42  184.60  1821.0  0.16500  0.86810  0.9387  0.2650   \n",
       "568  0.05884  ...  30.37   59.16   268.6  0.08996  0.06444  0.0000  0.0000   \n",
       "\n",
       "         28       29  30  \n",
       "0    0.4601  0.11890   0  \n",
       "1    0.2750  0.08902   0  \n",
       "2    0.3613  0.08758   0  \n",
       "3    0.6638  0.17300   0  \n",
       "4    0.2364  0.07678   0  \n",
       "..      ...      ...  ..  \n",
       "564  0.2060  0.07115   0  \n",
       "565  0.2572  0.06637   0  \n",
       "566  0.2218  0.07820   0  \n",
       "567  0.4087  0.12400   0  \n",
       "568  0.2871  0.07039   1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "\n",
    "def labelConvert(s):\n",
    "    s = s.strip().lower()\n",
    "    if s == \"m\":\n",
    "        return 0\n",
    "    if s == \"b\":\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "data = pd.read_csv(\"wdbc.data\",header = None, converters={30:labelConvert})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "picker = list(range(data.shape[0]))\n",
    "random.shuffle(picker)\n",
    "trainMax = int(len(picker) * TRAIN_TEST_RATIO)\n",
    "train = []\n",
    "test = []\n",
    "for pick in picker[:trainMax]:\n",
    "    train.append(list(data.values[pick]))\n",
    "for pick in picker[trainMax:]:\n",
    "    test.append(list(data.values[pick]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** :: We'll use linear discriminator classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.001, error=164.000\n",
      ">epoch=50, lrate=0.001, error=68.000\n",
      ">epoch=100, lrate=0.001, error=48.000\n",
      ">epoch=150, lrate=0.001, error=58.000\n",
      ">epoch=200, lrate=0.001, error=55.000\n",
      ">epoch=250, lrate=0.001, error=54.000\n",
      ">epoch=300, lrate=0.001, error=56.000\n",
      ">epoch=350, lrate=0.001, error=56.000\n",
      ">epoch=400, lrate=0.001, error=58.000\n",
      ">epoch=450, lrate=0.001, error=54.000\n",
      ">epoch=500, lrate=0.001, error=57.000\n",
      ">epoch=550, lrate=0.001, error=54.000\n",
      ">epoch=600, lrate=0.001, error=54.000\n",
      ">epoch=650, lrate=0.001, error=53.000\n",
      ">epoch=700, lrate=0.001, error=47.000\n",
      ">epoch=750, lrate=0.001, error=50.000\n",
      ">epoch=800, lrate=0.001, error=51.000\n",
      ">epoch=850, lrate=0.001, error=52.000\n",
      ">epoch=900, lrate=0.001, error=50.000\n",
      ">epoch=950, lrate=0.001, error=45.000\n",
      "[2.5189999999998336, 18.835765999997797, -10.685829999997841, 56.11929000000235, 1.2394999999999858, -0.2272226299999949, -1.6554385100002003, -2.471421556999758, -0.9384719450001979, -0.39775340000001363, -0.05014791999999954, 0.4445405000000287, -0.20635210000019807, -2.81203200000012, -13.180150999998204, -0.044210772000001834, -0.510538069999982, -0.6692340588001098, -0.1325294170000077, -0.14833422900000598, -0.05058075959999801, 19.552899999998637, -38.5443599999971, 20.608130000002344, -8.575100000000717, -0.5254508899999687, -5.332459689999059, -7.074114875999614, -1.6775073320000788, -1.6005834000002102, -0.46309425000002963]\n"
     ]
    }
   ],
   "source": [
    "def predict(row, weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i + 1] * row[i]\n",
    "    return 1.0 if activation >= 0.0 else 0.0\n",
    "\n",
    "### We are using an algorithm called gradient descent.\n",
    "### This will be taught in the future lectures.\n",
    "### You don't need to worry about it right now.\n",
    "def train_weights(train, l_rate, n_epoch):\n",
    "    weights = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0.0\n",
    "        for row in train:\n",
    "            prediction = predict(row, weights)\n",
    "            error = row[-1] - prediction\n",
    "            sum_error += error**2\n",
    "            weights[0] = weights[0] + l_rate * error\n",
    "            for i in range(len(row)-1):\n",
    "                weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n",
    "        if epoch % 50 == 0:\n",
    "            print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return weights\n",
    "\n",
    "## Do not worry about the hyperparameters of this algorithm right now.\n",
    "weights = train_weights(train, l_rate=0.001, n_epoch=1000)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** :: Use the predict function and the weights that was learnt to calculate the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "actual = []\n",
    "for row in test:\n",
    "    pred.append(predict(row, weights))\n",
    "    actual.append(row[-1])\n",
    "\n",
    "### You have preds and actuals now :)\n",
    "### Your Code Here\n",
    "def accuracy(pred,actual):\n",
    "    result = 0\n",
    "    for i in range(len(pred)):\n",
    "        if(pred[i] == actual[i]):\n",
    "            result = result + 1\n",
    "    print(\"Accuracy is \", result/len(pred));\n",
    "    \n",
    "accuracy(pred,actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionmatrix(actuals, prediction):\n",
    "    TruePositive = sum([int(a == 0 and p == 0) for a, p in zip(actuals, prediction)])\n",
    "    TrueNegative = sum([int(a == 1 and p == 1) for a, p in zip(actuals, prediction)])\n",
    "    FalsePositive = sum([int(a == 1 and p == 0) for a, p in zip(actuals, prediction)])\n",
    "    FalseNegative = sum([int(a == 0 and p == 1) for a, p in zip(actuals, prediction)])\n",
    "    return TruePositive, TrueNegative, FalsePositive, FalseNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 67 2 5\n"
     ]
    }
   ],
   "source": [
    "tp,tn,fp,fn = confusionmatrix(actual, pred)\n",
    "print(tp,tn,fp,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** :: Calculate precision\n",
    "\n",
    "$ p $ = $ tp $ $ / $ ($ tp $ + $ fp $)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precison is  0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "### Your Code Here\n",
    "precision = tp/(tp + fp)\n",
    "print(\"Precison is \",precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** :: Calculate recall \n",
    "\n",
    "$ r $ = $ tp $ $ /$ ( $ tp $ + $fn $ ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "### Your Code Here\n",
    "recall = tp/(tp+fn)\n",
    "print(\"Recall is \",recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** :: Calculate miss rate\n",
    "\n",
    "$ m $ = $ 1 $ $ - $ $ r $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss rate is  0.11111111111111116\n"
     ]
    }
   ],
   "source": [
    "### Your Code Here\n",
    "missrate = 1 - recall;\n",
    "print(\"miss rate is \",missrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** :: Calculate accuracy and check with earlier accuracy that we computed.\n",
    "\n",
    "$ a $ = ($ tp $ + $ tn $) / ($ tp $ + $ tn $ + $ fp $ + $ fn $ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "### Your Code Here\n",
    "acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "print(\"Accuracy is \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
