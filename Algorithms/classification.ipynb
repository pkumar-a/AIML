{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Special function to read special files\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class = horse\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize the images in CIFAR-10 Dataset\n",
    "## Here get_data unpickles the CIFAR Dataset and stores the data as 10000*3072 dimension in array X \n",
    "## and labels as 10000*1 dimension in array Y. \n",
    "## Visualize function shows the image corresponding to id number.\n",
    "\n",
    "def get_data(file):\n",
    "    dict = unpickle(file)\n",
    "    X = np.asarray(dict['data']).astype(\"uint8\")\n",
    "    Y = np.asarray(dict['labels'])\n",
    "    names = np.asarray(dict['filenames'])\n",
    "    list_class=(unpickle(\"cifar-10/batches.meta\")['label_names'])\n",
    "    return X,Y,names,list_class\n",
    "                     \n",
    "\n",
    "def visualize_image(X, Y, names, image_id):\n",
    "    rgb = X[image_id,:]\n",
    "    img = rgb.reshape(3, 32, 32).transpose([1, 2, 0])\n",
    "    print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.title(names[image_id])\n",
    "    plt.show()\n",
    "\n",
    "# Read image\n",
    "X, Y, names, classes = get_data(\"cifar-10/data_batch_3\")\n",
    "# Visualize the 10th image\n",
    "pick = 10\n",
    "print(\"Class =\",classes[Y[pick]])\n",
    "visualize_image(X, Y, names, pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear classifier code -\n",
    "# code to estimate optimal linear boundary,\n",
    "# classify train data by estimating the optimal linear boundary,\n",
    "# predict labels based on linear boundary,\n",
    "# and compute the accuracy of the classification\n",
    "\n",
    "# code to estimate optimal linear boundary (can ignore for now),\n",
    "def perceptron_sgd(X, Y):\n",
    "    w = np.zeros(len(X[0]))\n",
    "    eta = 0.01 # learning rate\n",
    "    epochs = 100\n",
    "    for t in range(epochs):\n",
    "        if (t+1) % 50 == 0:\n",
    "            print(\"Running Epoch #\", t+1)\n",
    "            # print(\"acc:\", compute_accuracy(predict(X[:, :-1], w), Y))\n",
    "        for i, x in enumerate(X):\n",
    "            if (np.dot(X[i], w) * Y[i]) <= 0:\n",
    "                w = w + eta * X[i] * Y[i]\n",
    "        eta *= 0.75\n",
    "    return w\n",
    "\n",
    "# classify train data by estimating the optimal linear boundary,\n",
    "def classify(train_feat, train_labels):\n",
    "    ## mapping first label to -1 and second to +1\n",
    "    labels = np.sort(np.unique(train_labels))\n",
    "    lmap = {labels[0] : -1, labels[1] : 1}\n",
    "    l = [lmap[i] for i in train_labels]     \n",
    "    ## appending 1 to train features\n",
    "    add_one2train = np.ones((len(train_feat), 1))\n",
    "    append_train_features = np.hstack((np.asarray(train_feat), add_one2train))\n",
    "    w = perceptron_sgd(append_train_features, l)\n",
    "    return w\n",
    "\n",
    "# predict labels based on linear boundary,\n",
    "def predict(features, w):\n",
    "    ##appending 1 to test features\n",
    "    add_one = np.ones((len(features),1))\n",
    "    append_features = np.hstack((np.asarray(features), add_one))\n",
    "    pred = np.dot(append_features, w)\n",
    "    return pred\n",
    "\n",
    "# compute the accuracy of the classification\n",
    "def compute_accuracy(pred, test_labels):\n",
    "    # To make it general, let us find the unique set of labels in test_labels\n",
    "    # (could be \"apples\" and \"oranges\", or \"1\" and \"2\"),\n",
    "    labels = np.sort(np.unique(test_labels))\n",
    "    # and then assign -1 and 1 to these unique labels\n",
    "    lmap = {labels[0] : -1, labels[1] : 1}\n",
    "    # Let's now convert the labels to -1 and 1\n",
    "    l = [lmap[i] for i in test_labels]\n",
    "    # Let us find the accuracy\n",
    "    p = []\n",
    "    for i in range(len(pred)):\n",
    "        p.append(1 if pred[i] >= 0 else -1)\n",
    "    acc = np.mean(np.asarray(p) == np.asarray(l))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for binary classification\n",
    "def one_vs_one_classifier_ours(train_features, train_labels):\n",
    "    w = classify(train_features, train_labels)\n",
    "    return w\n",
    "\n",
    "def calc_accuracy(X_test, Y_test, w):\n",
    "    pred = predict(X_test, w)\n",
    "    accuracy = compute_accuracy(pred, Y_test)\n",
    "    print(\"accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unpickling the data and labels from CIFAR-10 Dataset,\n",
    "## and Preparing the raw features for training and test data.\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "# Read all training features and labels\n",
    "for j in \"12345\": \n",
    "    batch_file = 'cifar-10/data_batch_'+ j\n",
    "    x_train, y_train, names_train, classes_train = get_data(batch_file)\n",
    "    X_train.extend(x_train)\n",
    "    Y_train.extend(y_train)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "\n",
    "# Read all test features and labels\n",
    "X_test, Y_test, names_test, classes_test = get_data(\"cifar-10/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_2classes(class0, class1, X, Y):\n",
    "    # Select class #0\n",
    "    X_0 = X[Y == class0]\n",
    "    Y_0 = Y[Y == class0]\n",
    "    # Select class #1\n",
    "    X_1 = X[Y == class1]\n",
    "    Y_1 = Y[Y == class1]\n",
    "    # Join the two classes to make the set\n",
    "    X_2classes = np.vstack((X_0, X_1))\n",
    "    Y_2classes = np.append(Y_0, Y_1)\n",
    "    return X_2classes, Y_2classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes #5 and #7\n",
    "X_train_2classes, Y_train_2classes = extract_2classes(5, 7, X_train, Y_train)\n",
    "X_test_2classes, Y_test_2classes = extract_2classes(5, 7, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "accuracy = 0.644\n"
     ]
    }
   ],
   "source": [
    "# Binary classification for classes 1 and 2 using hand features\n",
    "w = one_vs_one_classifier_ours(X_train_2classes, Y_train_2classes)\n",
    "\n",
    "# Find accuracy\n",
    "calc_accuracy(X_test_2classes, Y_test_2classes, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hand crafted features. For this we extracted 9 dimension feature for each image.\n",
    "## Feature consist of min, max and mean intensity values for RGB channel.\n",
    "\n",
    "# Extract min, max and mean of R, G, and B in each image\n",
    "# in train\n",
    "def extract_RGB_min_max_mean(X):\n",
    "    R, G, B = 1024, 2048, 3072\n",
    "    R_min = np.reshape(np.min(X[:, :R], axis=1), (len(X), 1))\n",
    "    R_max = np.reshape(np.max(X[:, :R], axis=1), (len(X), 1))\n",
    "    R_mean = np.reshape(np.mean(X[:, :R], axis=1), (len(X), 1))\n",
    "    G_min = np.reshape(np.min(X[:, R:G], axis=1), (len(X), 1))\n",
    "    G_max = np.reshape(np.max(X[:, R:G], axis=1), (len(X), 1))\n",
    "    G_mean = np.reshape(np.mean(X[:, R:G], axis=1), (len(X), 1))\n",
    "    B_min = np.reshape(np.min(X[:, G:B], axis=1), (len(X), 1))\n",
    "    B_max = np.reshape(np.max(X[:, G:B], axis=1), (len(X), 1))\n",
    "    B_mean = np.reshape(np.mean(X[:, G:B], axis=1), (len(X), 1))\n",
    "    return np.hstack((R_min, R_max, R_mean, G_min, G_max, G_mean, B_min, B_max, B_mean))\n",
    "\n",
    "head_features_train = extract_RGB_min_max_mean(X_train_2classes)\n",
    "head_features_test = extract_RGB_min_max_mean(X_test_2classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "accuracy = 0.5085\n"
     ]
    }
   ],
   "source": [
    "# Binary classification for classes 1 and 2 using hand features\n",
    "w = one_vs_one_classifier_ours(head_features_train, Y_train_2classes)\n",
    "\n",
    "# Find accuracy\n",
    "calc_accuracy(head_features_test, Y_test_2classes, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def extract_eigenvectors(k, X_train):\n",
    "    pca = PCA(n_components=k)\n",
    "    pca.fit(X_train)\n",
    "    eigen_vectors = pca.components_\n",
    "    return eigen_vectors, pca\n",
    "\n",
    "def make_pca_features(eigen_vectors, X):\n",
    "    return np.transpose(np.dot(eigen_vectors, np.transpose(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pca features\n",
    "k = 200\n",
    "eigen_vectors, pca_object = extract_eigenvectors(k, X_train_2classes)\n",
    "pca_features_train_2classes = make_pca_features(eigen_vectors, X_train_2classes)\n",
    "pca_features_test_2classes = make_pca_features(eigen_vectors, X_test_2classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "accuracy = 0.6385\n"
     ]
    }
   ],
   "source": [
    "# Binary classification for classes 1 and 2 using hand features\n",
    "w = one_vs_one_classifier_ours(pca_features_train_2classes, Y_train_2classes)\n",
    "\n",
    "# Find accuracy\n",
    "calc_accuracy(pca_features_test_2classes, Y_test_2classes, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with k = 800\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "accuracy = 0.6495\n",
      "Training with k = 1000\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "accuracy = 0.6455\n",
      "Training with k = 1200\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "accuracy = 0.6405\n",
      "Training with k = 1400\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "accuracy = 0.6445\n"
     ]
    }
   ],
   "source": [
    "## Try different k values\n",
    "for k in [800, 1000, 1200, 1400]:\n",
    "    print(\"Training with k =\", k)\n",
    "    # Make pca features\n",
    "    eigen_vectors, pca_object = extract_eigenvectors(k, X_train_2classes)\n",
    "    pca_features_train = make_pca_features(eigen_vectors, X_train_2classes)\n",
    "    pca_features_test = make_pca_features(eigen_vectors, X_test_2classes)\n",
    "    # Binary classification for classes 1 and 2 using hand features\n",
    "    w = one_vs_one_classifier_ours(pca_features_train, Y_train_2classes)\n",
    "    # Find accuracy\n",
    "    calc_accuracy(pca_features_test, Y_test_2classes, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the deep features of images\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "features = sio.loadmat('cifar-10/cifar10features.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 512) (50000,) (10000, 512) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Extracting the deep features into training and testing\n",
    "deep_features_train = features['x_train']\n",
    "deep_labels_train = np.squeeze(np.transpose(features['y_train']))\n",
    "deep_features_test = features['x_test']\n",
    "deep_labels_test = np.squeeze(np.transpose(features['y_test']))\n",
    "print(deep_features_train.shape, deep_labels_train.shape, deep_features_test.shape, deep_labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features of class0 and class1\n",
    "deep_features_train_2classes, deep_labels_train_2classes = extract_2classes(5, 7, deep_features_train, np.squeeze(deep_labels_train))\n",
    "deep_features_test_2classes, deep_labels_test_2classes = extract_2classes(5, 7, deep_features_test, np.squeeze(deep_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "accuracy = 0.9795\n"
     ]
    }
   ],
   "source": [
    "# Binary classification for classes 1 and 2 using hand features\n",
    "w = one_vs_one_classifier_ours(deep_features_train_2classes, deep_labels_train_2classes)\n",
    "\n",
    "# Find accuracy\n",
    "calc_accuracy(deep_features_test_2classes, deep_labels_test_2classes, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Raw features\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hand features for full training and test sets\n",
    "head_features_train = extract_RGB_min_max_mean(X_train)\n",
    "head_features_test = extract_RGB_min_max_mean(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 9) (10000, 9)\n"
     ]
    }
   ],
   "source": [
    "print(head_features_train.shape, head_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pca features for full training and test sets\n",
    "# Make pca features, with k=200\n",
    "k = 200\n",
    "eigen_vectors, pca_object = extract_eigenvectors(k, X_train)\n",
    "pca_features_train = make_pca_features(eigen_vectors, X_train)\n",
    "pca_features_test = make_pca_features(eigen_vectors, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 200) (10000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(pca_features_train.shape, pca_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 512) (10000, 512)\n"
     ]
    }
   ],
   "source": [
    "# Deep features\n",
    "print(deep_features_train.shape, deep_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import random\n",
    "import collections\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def extract_two_classes(data, x,y):\n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "    merged = []\n",
    "    merged.extend(data[x])\n",
    "    merged.extend(data[y])\n",
    "    random.shuffle(merged)\n",
    "    xtrain = list(zip(*merged))[0]\n",
    "    ytrain = list(zip(*merged))[1]\n",
    "    return xtrain, ytrain\n",
    "\n",
    "def oneVsone(data, num_classes, test_sample):\n",
    "    weight = []\n",
    "    prediction = []\n",
    "    for i, j in list(itertools.combinations(range(num_classes), 2)):\n",
    "        print(\"Training for classes\", i, j)\n",
    "        xtrain, ytrain = extract_two_classes(data, i,j)\n",
    "        w = classify(xtrain, ytrain)\n",
    "        weight.append((w,(i,j)))\n",
    "        pred = []\n",
    "        preds = predict(test_sample, w)\n",
    "        for p in predict(test_sample, w):\n",
    "            if p > 0:\n",
    "                pred.append(j)\n",
    "            else:\n",
    "                pred.append(i)\n",
    "        prediction.append(pred)\n",
    "        res = stats.mode(np.asarray(prediction))[0]\n",
    "    return np.squeeze(res)\n",
    "\n",
    "\n",
    "def multiclass_classification(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    ## Train features and labels you want to use\n",
    "    xtrain = X_train\n",
    "    ytrain = Y_train\n",
    "    ## Test features and labels you want to check on\n",
    "    xtest = X_test\n",
    "    ytest = Y_test\n",
    "\n",
    "    l = zip(xtrain,  ytrain)\n",
    "    #L.sort(key=lambda x: x[1])\n",
    "    L = sorted(l, key=lambda x: x[1])\n",
    "\n",
    "    it = itertools.groupby(L, operator.itemgetter(1))\n",
    "    All_classes = []\n",
    "\n",
    "    for key, subiter in it:\n",
    "#         print ('Class:', key)\n",
    "        data = []\n",
    "        for item in subiter:\n",
    "            data.append(item)\n",
    "        All_classes.append(data)\n",
    "\n",
    "    pred = oneVsone(All_classes, len(np.unique(Y_train)), xtest)\n",
    "    print(accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES & LABELS\n",
    "#HOMEWORK\n",
    "train_features = deep_features_train\n",
    "train_labels = Y_train\n",
    "test_features = deep_features_test\n",
    "test_labels = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for classes 0 1\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 0 2\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 0 3\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 0 4\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 0 5\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 0 6\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 0 7\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 0 8\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 0 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 1 2\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 1 3\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 1 4\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 1 5\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 1 6\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 1 7\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 1 8\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 1 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 2 3\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 2 4\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 2 5\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 2 6\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 2 7\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 2 8\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 2 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 3 4\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 3 5\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 3 6\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 3 7\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 3 8\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 3 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 4 5\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 4 6\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 4 7\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 4 8\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 4 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 5 6\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 5 7\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 5 8\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 5 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 6 7\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 6 8\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 6 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 7 8\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 7 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "Training for classes 8 9\n",
      "Running Epoch # 50\n",
      "Running Epoch # 100\n",
      "0.9351\n"
     ]
    }
   ],
   "source": [
    "multiclass_classification(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 5\n",
      "  5 5 5 6 6 6 7 7 8]\n",
      " [1 2 3 4 5 6 7 8 9 2 3 4 5 6 7 8 9 3 4 5 6 7 8 9 4 5 6 7 8 9 5 6 7 8 9 6\n",
      "  7 8 9 7 8 9 8 9 9]]\n"
     ]
    }
   ],
   "source": [
    "actual_labels = np.array([(i, j) for i in range(10) for j in range(i+1, 10)]).T\n",
    "\n",
    "print(actual_labels)\n",
    "\n",
    "def extract_2classes_with_binary_labels(i, j, X, Y):\n",
    "    # Select class #0\n",
    "    X_0 = X[Y == i]\n",
    "    Y_0 = np.zeros((len(X_0)))\n",
    "    # Select class #1\n",
    "    X_1 = X[Y == j]\n",
    "    Y_1 = np.ones((len(X_1)))\n",
    "    # Join the two classes to make the set\n",
    "    X_2classes = np.vstack((X_0, X_1))\n",
    "    Y_2classes = np.append(Y_0, Y_1)\n",
    "    return X_2classes, Y_2classes\n",
    "\n",
    "# one-vs-one classifier\n",
    "from sklearn import linear_model\n",
    "def one_vs_one_classifier(train_features, train_labels):\n",
    "    clf = linear_model.SGDClassifier(random_state=1)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def multiclass_classify_using_sklearn(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    classifiers = []\n",
    "    \n",
    "    # For each pair of classes:\n",
    "    for i in range(0, 9):\n",
    "        for j in range(i+1, 10):\n",
    "            print(\"Training pair of classes:\", i, j)\n",
    "            \n",
    "            # Extract the train features and labels of the two classes\n",
    "            train_features, train_labels = extract_2classes_with_binary_labels(i, j, X_train, Y_train)\n",
    "            \n",
    "            # Let us make each one-vs-one classifier\n",
    "            # Train the classifier on these features and labels\n",
    "            clf = one_vs_one_classifier(train_features, train_labels)\n",
    "            classifiers.append(clf)\n",
    "    \n",
    "    # Find each classifier's prediction\n",
    "    predicted_classes_from_all_classifiers = np.zeros((len(X_test), len(classifiers)), dtype=int)\n",
    "    for c, clf in enumerate(classifiers):\n",
    "        preds = np.asarray(clf.predict(X_test), dtype=int)\n",
    "        predicted_classes_from_all_classifiers[:, c] = actual_labels[preds, c]\n",
    "\n",
    "    # Take majority vote for each sample\n",
    "    predicted_classes = []\n",
    "    for p in predicted_classes_from_all_classifiers:\n",
    "        predicted_classes.append(np.argmax(np.bincount(p)))\n",
    "    \n",
    "    # Find accuracy\n",
    "    test_accuracy = np.mean(predicted_classes == Y_test)\n",
    "    print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pair of classes: 0 1\n",
      "Training pair of classes: 0 2\n",
      "Training pair of classes: 0 3\n",
      "Training pair of classes: 0 4\n",
      "Training pair of classes: 0 5\n",
      "Training pair of classes: 0 6\n",
      "Training pair of classes: 0 7\n",
      "Training pair of classes: 0 8\n",
      "Training pair of classes: 0 9\n",
      "Training pair of classes: 1 2\n",
      "Training pair of classes: 1 3\n",
      "Training pair of classes: 1 4\n",
      "Training pair of classes: 1 5\n",
      "Training pair of classes: 1 6\n",
      "Training pair of classes: 1 7\n",
      "Training pair of classes: 1 8\n",
      "Training pair of classes: 1 9\n",
      "Training pair of classes: 2 3\n",
      "Training pair of classes: 2 4\n",
      "Training pair of classes: 2 5\n",
      "Training pair of classes: 2 6\n",
      "Training pair of classes: 2 7\n",
      "Training pair of classes: 2 8\n",
      "Training pair of classes: 2 9\n",
      "Training pair of classes: 3 4\n",
      "Training pair of classes: 3 5\n",
      "Training pair of classes: 3 6\n",
      "Training pair of classes: 3 7\n",
      "Training pair of classes: 3 8\n",
      "Training pair of classes: 3 9\n",
      "Training pair of classes: 4 5\n",
      "Training pair of classes: 4 6\n",
      "Training pair of classes: 4 7\n",
      "Training pair of classes: 4 8\n",
      "Training pair of classes: 4 9\n",
      "Training pair of classes: 5 6\n",
      "Training pair of classes: 5 7\n",
      "Training pair of classes: 5 8\n",
      "Training pair of classes: 5 9\n",
      "Training pair of classes: 6 7\n",
      "Training pair of classes: 6 8\n",
      "Training pair of classes: 6 9\n",
      "Training pair of classes: 7 8\n",
      "Training pair of classes: 7 9\n",
      "Training pair of classes: 8 9\n",
      "0.9333\n"
     ]
    }
   ],
   "source": [
    "multiclass_classify_using_sklearn(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
